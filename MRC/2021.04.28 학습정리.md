# 학습정리

**Passage Retrieval**

질문(query)에 맞는 문서를 찾는 것

query와 passage를 임베딩한 뒤 유사도로 랭킹을 매기고 유사도가 가장 높은 Passage를 선택

​         

**Passage Embedding**

Passage Embedding의 벡터 공간, Passage 간 유사도 등을 알고리즘으로 계산할 수 있다.

​          

**Sparse Embedding**

BoW -> n-gram으로 구성 (1 ~ 3), n이 커질수록 embedding vector가 크게 증가한다.

Term value -> binary (Term이 문서에 등장하는가?), frequency (몇 번 등장하는가?)

의미가 비슷하지만 다른 단어인 경우 비교하지 못한다.

​         

**TF-IDF**

TF (단어의 등장 빈도)

IDF(단어가 제공하는 정보의 양) - 적게 등장 할 수 록  많은 정보를 포함하고있다고 판단

유사도

- 사용자가 입력한 질문을 토큰화
- 단어 사전에 없는 토큰들은 제외
- 질의를 하나의 문서로 생각하고 이에 대한 TF-IDF값 계산
- 질의 RF-IDF값과 각 문서별 TF-IDF 값을 곱하여 유사도 점수 계산
- 가장 높은 점수를 가지는 문서 선택

​         

**BM25**

문서의 길이 까지 고려하여 점수를 매기는 방법 (짧은 문서에서 매칭될 경우 더 큰 가중치)

아직까지 사용이 많이 되는 알고리즘



Passage Retrieval + MRC => Open domain Question Answering



## 오늘 한 것

baseline code 수정

실수 때문에 하루를 날린기분.... 체크 잘하자

​        

### 해볼 것

다른 Retrieval 방식 사용해보기 (피어세션에서 나온 것들)

코드 수정 

