# 학습정리

### 오늘 시도해 본것

- Tokenizer, 데이터 전처리 공부

  - competition 주어진 데이터셋은 어느정도 nomalize되어 있다고 생각된다.

    => competition 주어진 데이터셋으로 tokenizer를 만들어 사용할 때 nomalize 할 필요성이 있을까?

  - 이후 형태소 단위 tokenize, WordPice tokenize 시도

- 새로 작성한 baseline코드를 이용하여 학습

  - acc : 76.0%

- Data argumentation 시도

  - 데이터 분포를 확인해 본 결과 데이터가 매우 심하게 불균형
  - 적은 label의 데이터를 이름과 단체만 변경해주는 방식(200개)으로 argumenation하여 csv 파일생성
  - 학습 진행중

​           

### 시도해 볼 것

- Argumentation 데이터 증가 개수 변경해서 학습해보기
- Tokenizer (형태소 단위, WordPice) 작성하여 학습시켜 AutoTokenizer과 비교해보기
- Argumentation이 크게 효과가 없다면 외부 데이터를 이용하여 더 큰 데이터셋으로 학습해보기
  - https://github.com/machinereading/kor-re-gold



### 궁금점

- 오늘 배운 데이터 전처리 강의에서 활용된 raw data와 강의가 지나고 전처리가 된 data를 대회에서 제공된 data와 비교했을 때 이미 전처리가 완료된 data와 더 유사하다고 판단되는데 전처리가 더 필요할까?
- 많은 양의 데이터로 이미 pretrained 된 tokenizer 보다 좋은 성능이 나올까?

 